{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage as ski\n",
    "import skimage.morphology as mp\n",
    "from skimage import io, feature,filters\n",
    "from skimage import img_as_float\n",
    "from skimage.color import rgb2hsv,rgb2gray,hsv2rgb\n",
    "from skimage.filters.edges import convolve\n",
    "from skimage.morphology import disk\n",
    "import warnings\n",
    "from matplotlib import pylab as plt\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import os\n",
    "from skimage.morphology import flood_fill\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(path):\n",
    "    img=io.imread(path)\n",
    "    return img\n",
    "def convert2gray(img):\n",
    "    return(img_as_float(rgb2gray(img)))\n",
    "def preProcess(img):\n",
    "    img=convert2gray(img)\n",
    "    img=filters.gaussian(img,sigma=5) \n",
    "    img=img**0.4\n",
    "    return img\n",
    "def process(img):\n",
    "    img=filters.sobel(img)\n",
    "    MIN = np.min(img)\n",
    "    MAX = np.max(img)\n",
    "    img = (img - MIN) / (MAX - MIN)\n",
    "    img[img[:,:] > 1] = 1\n",
    "    img[img[:,:] < 0] = 0\n",
    "    img=img*(img>np.percentile(img,80))\n",
    "    img=(img>0)*1.0\n",
    "\n",
    "    return img\n",
    "def postProcess(img,mask):\n",
    "    img=mp.dilation(img,selem=disk(10))\n",
    "    img=mp.erosion(img,selem=disk(15))\n",
    "    mask=convert2gray(mask)\n",
    "    for i in range(20):\n",
    "        mask=mp.erosion(mask)\n",
    "    img=img*mask\n",
    "\n",
    "    return img\n",
    "def createResult(base,img):\n",
    "    for b,i in zip(base,img):\n",
    "        for c,j in zip(b,i):\n",
    "            if j==1:\n",
    "                c[0]=255\n",
    "                c[1]=255\n",
    "                c[2]=255\n",
    "\n",
    "    return base\n",
    "def wholeProcess(base,mask):\n",
    "    img=preProcess(base)\n",
    "    img=process(img)\n",
    "    img=postProcess(img,mask)\n",
    "    base=createResult(base,img)\n",
    "    return base, img\n",
    "def getFileNames(path):\n",
    "    return os.listdir(path)\n",
    "def takeFewExamples(amount):\n",
    "    images=getFileNames(os.getcwd()+\"\\\\images\")\n",
    "    chosenImages=random.sample(images,amount)\n",
    "    names=[]\n",
    "    imagesPaths=[]\n",
    "    masksPaths=[]\n",
    "    manualPaths=[]\n",
    "    for i in chosenImages:\n",
    "        names.append(i[:-4])\n",
    "    for i in names:\n",
    "        imagesPaths.append(os.getcwd()+\"\\\\images\\\\\"+i+\".jpg\")\n",
    "        masksPaths.append(os.getcwd()+\"\\\\mask\\\\\"+i+\"_mask.tif\")\n",
    "        manualPaths.append(os.getcwd()+\"\\\\manual1\\\\\"+i+\".tif\")\n",
    "    return imagesPaths, masksPaths, manualPaths\n",
    "def takeAll():\n",
    "    images=getFileNames(os.getcwd()+\"\\\\images\")\n",
    "    names=[]\n",
    "    imagesPaths=[]\n",
    "    masksPaths=[]\n",
    "    manualPaths=[]\n",
    "    for i in images:\n",
    "        names.append(i[:-4])\n",
    "    for i in names:\n",
    "        imagesPaths.append(os.getcwd()+\"\\\\images\\\\\"+i+\".jpg\")\n",
    "        masksPaths.append(os.getcwd()+\"\\\\mask\\\\\"+i+\"_mask.tif\")\n",
    "        manualPaths.append(os.getcwd()+\"\\\\manual1\\\\\"+i+\".tif\")\n",
    "    return imagesPaths, masksPaths, manualPaths\n",
    "def showImages(images):\n",
    "    for i in range(1,len(images)+1):\n",
    "        showImg(images[i-1])\n",
    "\n",
    "def showImg(img):\n",
    "    fig=plt.figure(figsize=(20,10))\n",
    "    plt.imshow(img)\n",
    "def countStatistics(image, manual1,masks):\n",
    "    total=0\n",
    "    TP=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    TN=0\n",
    "    for img,man,mask in zip(image,manual1,masks):\n",
    "        for i,j,k in zip(img,man,mask):\n",
    "           \n",
    "            if k==1:\n",
    "                if j==i==0:\n",
    "                    TN+=1\n",
    "                if j==i==1:\n",
    "                    TP+=1\n",
    "                if i==0 and j==1:\n",
    "                    FN+=1\n",
    "                if i==1 and j==0:\n",
    "                    FP+=1\n",
    "                total+=1\n",
    "    accuracy=(TP+TN)/total\n",
    "    sensitivity=TP/(TP+FN)\n",
    "    precision=TP/(FP+TP)\n",
    "    specificity=TN/(FP+TN)\n",
    "    return accuracy,sensitivity,precision,specificity\n",
    "def printStatistics(tup):\n",
    "    print(\"Accuracy: \"+str(tup[0]))\n",
    "    print(\"Sensitivity: \"+str(tup[1]))\n",
    "    print(\"Precision: \"+str(tup[2]))\n",
    "    print(\"Specificity: \"+str(tup[3]))\n",
    "                    \n",
    "def divideImg(size=5,amount=200):   #returns data and target in lists\n",
    "    imagesPaths,masksPaths,manualPaths=takeAll()\n",
    "    half=size//2\n",
    "    transform=ToTensor()\n",
    "    allPositive=[]\n",
    "    allNegative=[]\n",
    "    for image,maskP,manualP in zip(imagesPaths,masksPaths,manualPaths):\n",
    "        img=img_as_float(readFile(image))\n",
    "\n",
    "        mask=convert2gray(readFile(maskP))\n",
    "        manual=convert2gray(readFile(manualP))\n",
    "        positive=[]\n",
    "        negative=[]\n",
    "        while (len(positive)<amount) or (len(negative)<amount):\n",
    "            x=random.randint(half,len(img)-half-1)\n",
    "            y=random.randint(half,len(img[0])-half-1)\n",
    "            if mask[x][y]==1:\n",
    "                if manual[x][y]==1:\n",
    "                    if len(positive)<amount:\n",
    "\n",
    "                        positive.append(img[x-half:x+half+1,y-half:y+half+1])\n",
    "                else:\n",
    "                    if len(negative)<amount:\n",
    "                        negative.append(img[x-half:x+half+1,y-half:y+half+1])\n",
    "        allPositive+=positive\n",
    "        allNegative+=negative\n",
    "        labels=np.ones(len(allPositive)+len(allNegative))\n",
    "        labels[len(allPositive):]=0\n",
    "        allImgs=allPositive+allNegative\n",
    "    return allImgs,labels\n",
    "\n",
    "def prepareDataset(x,y):\n",
    "    kfold=KFold(5,True,1)\n",
    "    data=TensorDataset(torch.Tensor(x).permute(0, 3, 1, 2),torch.Tensor(y))    #permute for changing from NHWC to NCHW\n",
    "    return kfold,data\n",
    "def prepareLoaders(trainData,testData,batchSize):\n",
    "    trainLoader=DataLoader(dataset=trainData,batch_size=batchSize,shuffle=True)\n",
    "    testLoader=DataLoader(dataset=testData,batch_size=len(testData))\n",
    "    return trainLoader,testLoader\n",
    "def prepareModel():\n",
    "    layers=[]\n",
    "    layers.append(nn.Conv2d(3,12,3,stride=1,padding=1))\n",
    "    layers.append(nn.ReLU())\n",
    "    layers.append(nn.Conv2d(12,24,3,stride=1,padding=1))\n",
    "    layers.append(nn.ReLU())\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2))\n",
    "    layers.append(nn.Flatten())\n",
    "    layers.append(nn.Linear(24*4,2))\n",
    "    return layers\n",
    "    \n",
    "def compute_acc(logits, expected):\n",
    "    pred = logits.argmax(dim=1)\n",
    "    return (pred == expected).type(torch.float).mean()\n",
    "def train(kfold,data,layers):\n",
    "    max_epoch = 10000\n",
    "    no_improvement = 5\n",
    "    batchSize=200\n",
    "    models=[]\n",
    "    accs=[]\n",
    "    for i in range(5):   #k-fold-cross-validation\n",
    "        model=nn.Sequential(*layers)\n",
    "        cost=torch.nn.CrossEntropyLoss()\n",
    "        opt=optim.Adam(model.parameters())\n",
    "        sets=next(kfold.split(data),None)\n",
    "        trainLoader,testLoader=prepareLoaders(TensorDataset(data[sets[0]][0],data[sets[0]][1]),\n",
    "                                              TensorDataset(data[sets[1]][0],data[sets[1]][1]),\n",
    "                                               batchSize)\n",
    "        train_loss = []\n",
    "        validation_acc = []\n",
    "        best_model = None\n",
    "        best_acc = None\n",
    "        best_epoch = None\n",
    "\n",
    "\n",
    "        for n_epoch in range(max_epoch):\n",
    "            model.train()\n",
    "            epoch_loss = []\n",
    "            for X_batch, y_batch in trainLoader:\n",
    "                opt.zero_grad()\n",
    "                logits = model(X_batch)\n",
    "                loss = cost(logits, y_batch.long())\n",
    "                loss.backward()\n",
    "                opt.step()        \n",
    "                epoch_loss.append(loss.detach())\n",
    "            train_loss.append(torch.tensor(epoch_loss).mean())\n",
    "            model.eval()\n",
    "            X, y = next(iter(testLoader))\n",
    "            logits = model(X)\n",
    "            acc = compute_acc(logits, y).detach()\n",
    "            validation_acc.append(acc)\n",
    "            if best_acc is None or acc > best_acc:\n",
    "                print(\"New best epoch \", n_epoch, \"acc\", acc)\n",
    "                best_acc = acc\n",
    "                best_model = model.state_dict()\n",
    "                best_epoch = n_epoch\n",
    "            if best_epoch + no_improvement <= n_epoch:\n",
    "                print(\"No improvement for\", no_improvement, \"epochs\")\n",
    "                break\n",
    "        \n",
    "        model.load_state_dict(best_model)\n",
    "        models.append(model)\n",
    "        accs.append(best_acc)\n",
    "    return accs,models\n",
    "def chooseBestModel(models,accs):\n",
    "    return models[accs.index(max(accs))]\n",
    "def getTestFragment():\n",
    "    half=2\n",
    "    imagesPaths,masksPaths,manualPaths=takeFewExamples(1)\n",
    "    for image,maskP,manualP in zip(imagesPaths,masksPaths,manualPaths):\n",
    "        b=readFile(image)\n",
    "        mask=readFile(maskP)\n",
    "        manual=convert2gray(readFile(manualP))\n",
    "        base=b.copy()\n",
    "        newBase,res=wholeProcess(base.copy(),mask.copy())\n",
    "        small=[]\n",
    "        man=manual[30*len(manual)//100:len(manual)*40//100,30*len(manual[0])//100:len(manual[0])*40//100]\n",
    "        img=base[30*len(base)//100:len(base)*40//100,30*len(base[0])//100:len(base[0])*40//100]\n",
    "        for i in range(30*len(base)//100,len(base)*40//100):\n",
    "            for j in range(30*len(base[0])//100,40*len(base[0])//100):\n",
    "                small.append(base[i-half:i+half+1,j-half:j+half+1])\n",
    "        showImg(img)\n",
    "        return small,img,man\n",
    "def checkModel(model,small,img,man):\n",
    "        data=TensorDataset(torch.Tensor(small).permute(0, 3, 1, 2))\n",
    "        \n",
    "        loader=DataLoader(data,batch_size=len(data))\n",
    "        X=next(iter(loader))\n",
    "        correct=0\n",
    "        logits = model(X[0])\n",
    "        binY=logits.argmax(dim=1)\n",
    "        print(binY)\n",
    "        print(man)\n",
    "        for i in range(len(img)):\n",
    "            for j in range(len(img[0])):\n",
    "                if binY[i*len(img)+j]==man[i][j]:\n",
    "                    correct+=1\n",
    "                if binY[i*len(img)+j]==1:\n",
    "                    img[i][j][0]=255\n",
    "                    img[i][j][1]=255\n",
    "                    img[i][j][2]=255\n",
    "        showImg(img)\n",
    "        print(correct/len(img)*len(img[0]))\n",
    "        print(len(small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def normalMethod():\n",
    "    imagesPaths,masksPaths,manualPaths=takeFewExamples(1)\n",
    "    for image,maskP,manualP in zip(imagesPaths,masksPaths,manualPaths):\n",
    "        base=readFile(image)\n",
    "        mask=readFile(maskP)\n",
    "        manual=readFile(manualP)\n",
    "        newBase,res=wholeProcess(base.copy(),mask.copy())\n",
    "        showImages([base,newBase,res])\n",
    "        printStatistics(countStatistics(res,convert2gray(manual),convert2gray(mask)))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalMethod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allImgs,labels=divideImg()\n",
    "kfold,data=prepareDataset(allImgs,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best epoch  0 acc tensor(0.6325)\n",
      "New best epoch  1 acc tensor(0.6622)\n",
      "New best epoch  3 acc tensor(0.6644)\n",
      "New best epoch  4 acc tensor(0.6717)\n",
      "New best epoch  5 acc tensor(0.6731)\n",
      "No improvement for 5 epochs\n"
     ]
    }
   ],
   "source": [
    "layers=prepareModel()\n",
    "accs,models=train(kfold,data,layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=chooseBestModel(models,accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small,img,man=getTestFragment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkModel(model,np.array(small),img,man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
